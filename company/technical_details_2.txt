Main
====
	Make a second init project
	Use the system Github
	Work towards using the Google platform
	
	For the project:
		Buid Link collector to formulate a tree for child-parent view.
		Use classifier and inspect to collect the information.				(1)
		
		Store the records into pandas dataframe and then into SQL Server.
		utilize the item class to build the pandas dataframes				(2)
		
		Build a second spider to collect utility information.				(3)
		
		Expand the search to surrounding domains. Look into:				(4)
			* linked-in 
			* Twitter 
			* wikipedia 

		Steps 1 and 2 are needed first, steps 3 and 4 requires documentation
	
	Look into data visualization and google services sentdexx
			
Key reason to backend solution, state!!
	
Dash and Django
	https://www.youtube.com/watch?v=QWZXJlhjgrs
	
	
Data
----
	Network for site
		Website title (ID)
			Nedlaw
		
		Domain 
			nedlaw.eu

		Internal websites
		External websites
		Menu linked websites
			
	Owner for domain
		Name
		Email
		phone
		Linked-in - search name + company, email, phone 
		Twitter - phone or email

	Terminology for domain
		Keyword
			Taxonomy
			'banking (3 items)',
             'business (2 items)',
             'cheat-sheet (3 items)',
             'climate (4 items)',
             'corruption (6 items)',
             'economics (11 items)',
             'election (6 items)',
             'law (16 items)',
             'media (10 items)',
             'politics (33 items)',
             'post-truth (8 items)',
             'programming (3 items)',
             'system (2 items)',
             'war (4 items)']  

		Link to keyword using wikipedia - done.

    '''
    
			
		Wikipedia API
			
			/root/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, 
			so I'm using the best available HTML parser for this system ("lxml"). This usually isn't a problem, 
			but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.

			The code that caused this warning is on line 193 of the file /root/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:

				 BeautifulSoup(YOUR_MARKUP})

				to this:

				 BeautifulSoup(YOUR_MARKUP, "lxml")

				  markup_type=markup_type))


Python
------

	Brief collection of the libraries needed to provide a product.

		Processing the meta-model for websites.  
			
			"Scrapy is a fast high-level web crawling and web scraping framework, used to crawl websites and extract structured data from their pages. 
			It can be used for a wide range of purposes, from data mining to monitoring and automated testing.".	
		
			Scrapy
				https://scrapy.org/
				
					https://doc.scrapy.org/en/latest/topics/stats.html
					https://doc.scrapy.org/en/1.0/topics/spider-middleware.html
					

			The first part of the problem is to collect the specific details in a relativly automated way and put the resuults in a database.
			This stage might have more than one iteration.
			The task has difficulty due to the relative unstructured nature of websites.
			
			scrapy shell at nedlaw 
			
				Main menu items			 : response.xpath("//div[contains (@class, 'hs-menu')]/ul/li/a").extract()
				
					Out[18]: 
					['<a href="https://www.nedlaw.eu/#hs-about-us-section">About</a>',
					 '<a href="https://www.nedlaw.eu/#hs-portfolio-section">Editorial</a>',
					 '<a href="https://www.nedlaw.eu/#hs-service-post-section">Identity</a>',
					 '<a href="https://www.nedlaw.eu/#hs-blog-section">Archive</a>',
					 '<a href="https://www.nedlaw.eu/#hs-contact-section">Contact</a>',
					 '<a href="https://www.nedlaw.eu/blog/">Blog</a>',
					 '<a href="https://www.nedlaw.eu/entrepreneurship/">Business</a>',
					 '<a href="https://nedlaw.eu/map/">Map</a>']

				
				Main menu, sub menu items: response.xpath("//div[contains (@class, 'hs-menu')]/ul/li[contains (@class, 'menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-2526')]/ul/li/a").extract()
					
					Out[25]: 
					['<a href="https://www.nedlaw.eu/plan-of-business/">Plan of Business</a>',
					 '<a href="https://www.nedlaw.eu/theory-of-funnel/">Theory of Funnel</a>',
					 '<a href="https://www.nedlaw.eu/daily-operations/">Daily Operations</a>',
					 '<a href="https://www.nedlaw.eu/working-capital/">Working Capital</a>',
					 '<a href="https://www.nedlaw.eu/profiling/">Profiling</a>',
					 '<a href="https://www.nedlaw.eu/values/">Values</a>',
					 '<a href="https://www.nedlaw.eu/external-resources/">External Resources</a>']
					 
				Sub section response.xpath("//div[contains (@class, 'hs-service-excerpt')]/h6/a").extract()

					Out[3]: 
					['<a href="https://www.nedlaw.eu/development/">Development</a>',
					 '<a href="https://www.nedlaw.eu/politics/">Political views</a>',
					 '<a href="https://www.nedlaw.eu/systems/">Systems</a>',
					 '<a href="https://www.nedlaw.eu/intelligence/">“Superior Intelligence”</a>',
					 '<a href="https://www.nedlaw.eu/idea-for-business/">Idea for Business</a>']
					 
				Footer links response.xpath("//li[contains (@class, 'simple-links-item simple-links-widget-item')]/a").extract()

					Out[4]: 
					['<a href="https://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/" target="_blank" title="Twitter/python library. Link related: https://github.com/AnnaVM/Twitter_API" rel="nofollow">Tweepy</a>',
					 '<a href="https://github.com/Esri/arcgis-python-api/tree/master/guide" target="_blank" title="Python projects to generate and execute ESRI maps." rel="nofollow">Esri Arcgis API</a>',
					 '<a href="https://github.com/jupyter/jupyter/wiki/A-gallery-of-interesting-Jupyter-Notebooks" target="_blank" title="Index-page for open python projects.">Python Index</a>',
					 '<a href="https://arachnoid.com/IPython/index.html" target="_blank" title="Python programming">Mathematical programming</a>',
					 '<a href="http://systems-sciences.uni-graz.at/etextbook/" target="_blank" title="">System paradigm</a>',
					 '<a href="https://neo4j.com/developer/" target="_blank" title="Client and server side packages for RDF.">Graph programming Neo4J</a>',
					 '<a href="https://franz.com/agraph/allegrograph/" target="_blank" title="">Allegro-Graph RDF</a>']

				Tag cloud: response.xpath("//div[contains (@class, 'tagcloud')]/a").extract()

					Out[5]: 
					['<a href="https://www.nedlaw.eu/tag/tag_banking/" class="tag-cloud-link tag-link-43 tag-link-position-1" style="font-size: 11.414634146341pt;" aria-label="banking (3 items)">banking</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_business/" class="tag-cloud-link tag-link-35 tag-link-position-2" style="font-size: 10.048780487805pt;" aria-label="business (2 items)">business</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_cheatsheet/" class="tag-cloud-link tag-link-37 tag-link-position-3" style="font-size: 11.414634146341pt;" aria-label="cheat-sheet (3 items)">cheat-sheet</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_climate/" class="tag-cloud-link tag-link-46 tag-link-position-4" style="font-size: 12.552845528455pt;" aria-label="climate (4 items)">climate</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_corruption/" class="tag-cloud-link tag-link-48 tag-link-position-5" style="font-size: 14.260162601626pt;" aria-label="corruption (6 items)">corruption</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_economy/" class="tag-cloud-link tag-link-42 tag-link-position-6" style="font-size: 16.878048780488pt;" aria-label="economics (11 items)">economics</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_election/" class="tag-cloud-link tag-link-40 tag-link-position-7" style="font-size: 14.260162601626pt;" aria-label="election (6 items)">election</a>',
					 '<a href="https://www.nedlaw.eu/tag/elections/" class="tag-cloud-link tag-link-61 tag-link-position-8" style="font-size: 8pt;" aria-label="elections (1 item)">elections</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_law/" class="tag-cloud-link tag-link-33 tag-link-position-9" style="font-size: 18.585365853659pt;" aria-label="law (16 items)">law</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_media/" class="tag-cloud-link tag-link-31 tag-link-position-10" style="font-size: 16.422764227642pt;" aria-label="media (10 items)">media</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_politics/" class="tag-cloud-link tag-link-44 tag-link-position-11" style="font-size: 22pt;" aria-label="politics (33 items)">politics</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_post_truth/" class="tag-cloud-link tag-link-39 tag-link-position-12" style="font-size: 15.39837398374pt;" aria-label="post-truth (8 items)">post-truth</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_programming/" class="tag-cloud-link tag-link-47 tag-link-position-13" style="font-size: 11.414634146341pt;" aria-label="programming (3 items)">programming</a>',
					 '<a href="https://www.nedlaw.eu/tag/tag_system/" class="tag-cloud-link tag-link-50 tag-link-position-14" style="font-size: 10.048780487805pt;" aria-label="system (2 items)">system</a>',
					 '<a href="https://www.nedlaw.eu/tag/war/" class="tag-cloud-link tag-link-62 tag-link-position-15" style="font-size: 12.552845528455pt;" aria-label="war (4 items)">war</a>']
 
			To do, run scrapy as an agent.
			Find the code for scrapy

		Visualization:

			If collecting the data is the first problem, then the second problem is producing the information in visual-form.
			This stage doesn't, however, address the issue of the method of producing the information.
			
			This is dictated by the type of the visualization type.
			Thus, it is the problem of chicken and egg.
			Dash is light python based python platform for web based vizualization.
		
			Dash py Plotly - https://plot.ly/products/dash/
			
				Tutorial tree
					https://dash.plot.ly/
				
				Tree based visualization
					https://github.com/plotly/dash-network
					https://beta.observablehq.com/@mbostock/d3-force-directed-graph
					
				Dash Boiler-plate - ?
					https://github.com/plotly/dash-component-boilerplate
					
					
		Web-platform
		
			To mediate the visualization requires a platform.
		
			Django 
					
				Main documentation
				
					https://www.djangoproject.com/
				
				Google
				
					Google Python-platform
						https://cloud.google.com/python/docs/
						
					Getting Started With Django
						https://cloud.google.com/python/django/
						
					Python Bookshelf App
						https://cloud.google.com/python/getting-started/tutorial-app

			Django is a web-platform with the internel mechanics of defining a model.
			The model contains named variables.
			
			The relationship is information produced is mirror the data-model for scrapy and Dash.
				Embed the Dash visualizations within Django.
				And use the modelling capabilities of Django to gather the information needed for each visualization.
				
		
		Disc profiling metrics

			https://en.wikipedia.org/wiki/Fluid_and_crystallized_intelligence
			https://en.wikipedia.org/wiki/Openness_to_experience
			https://en.wikipedia.org/wiki/Agreeableness
			https://en.wikipedia.org/wiki/Startup_accelerator
		
	Geo location Python

		import re
		import json
		from urllib2 import urlopen

		url = 'http://ipinfo.io/json'
		response = urlopen(url)
		data = json.load(response)

		IP=data['ip']
		org=data['org']
		city = data['city']
		country=data['country']
		region=data['region']

		print 'Your IP detail\n '
		print 'IP : {4} \nRegion : {1} \nCountry : {2} \nCity : {3} \nOrg : {0}'.format(org,region,country,city,IP)	
		